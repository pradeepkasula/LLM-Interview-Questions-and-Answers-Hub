Authored by **Kalyan KS**. You can follow him on [Twitter](https://x.com/kalyan_kpl) and [LinkedIn](https://www.linkedin.com/in/kalyanksnlp/) for the latest LLM, RAG and Agent updates.

## ğŸ“Œ Q94: What are the strengths and limitations of full fine-tuning?

### âœ… Answer

Full fine-tuning involves updating all parameters of a pre-trained LLM.  Its primary strength is achieving the highest possible performance because the model is fully adapted, potentially leading to state-of-the-art results. However, its major limitations include 

- being computationally expensive and time-consuming, demanding significant GPU resources, large storage for the full model checkpoints, and 

- a high risk of catastrophic forgetting, where the model loses its general knowledge acquired during pre-training.

## ğŸ“Œ Q95: Explain how parameter efficient fine-tuning addresses the limitations of full fine-tuning.

### âœ… Answer

Parameter-efficient fine-tuning (PEFT) addresses the limitations of full fine-tuning by updating only a small subset of model parameters or adding lightweight modules (introducing a minimal number of new, trainable parameters) while keeping the majority of the pre-trained model weights frozen. This approach significantly reduces computational costs, memory usage, and storage requirements compared to full fine-tuning, which updates all parameters and demands high resources. 

PEFT also mitigates the risk of catastrophic forgetting and overfitting that full fine-tuning faces by preserving the original pre-trained knowledge. Additionally, PEFT enables faster training and easier deployment on edge devices or resource-constrained environments, making it more scalable and cost-effective without sacrificing performance. This balance of efficiency and effectiveness makes PEFT a practical solution for adapting large language models across multiple domains and tasks.


## ğŸ“Œ Q96: When might prompt engineering be preferred over task-specific fine-tuning?

### âœ… Answer

Prompt engineering is generally preferred over task-specific fine-tuning when the task is complex or open-ended, requiring the LLMâ€™s broad general knowledge and in-context learning abilities to solve it. 

It is also the better choice when data for fine-tuning is scarce or if rapid iteration and experimentation are needed, as modifying a prompt is significantly faster and more resource-efficient than fine-tuning the model. Furthermore, if a single LLM must handle a variety of diverse tasks , prompt engineering is preferred, as it avoids creating and deploying a separate fine-tuned model for each.

## **ğŸš€ AIxFunda Newsletter (free)**


Join ğŸš€ AIxFunda free newsletter to get the latest updates and interesting tutorials related to Generative AI, LLMs, Agents and RAG.

- âœ¨ Weekly GenAI updates.
- ğŸ“„ Weekly LLM, Agents and RAG paper updates.
- ğŸ“ 1 fresh blog post on an interesting topic every week.

ğŸ‘‰ [Subcribe Now](https://aixfunda.substack.com/) 

---------------------------------------------------------------------------------------------




