Authored by **Kalyan KS**. You can follow him on [Twitter](https://x.com/kalyan_kpl) and [LinkedIn](https://www.linkedin.com/in/kalyanksnlp/) for the latest LLM, RAG and Agent updates.

## ğŸ“Œ Q25: Explain how masking works in masked self-attention in Transformer.

### âœ… Answer

Masking in masked self-attention (used in the Transformer's decoder) prevents the model from attending to future tokens in the sequence. It's achieved by setting the attention scores for those future positions to a very large negative number (like âˆ’âˆ), so that the softmax function turns them into zero. This ensures that the prediction for the current token only relies on the known preceding tokens, preserving the auto-regressive property.

## ğŸ“Œ Q26: Explain why self-attention in the decoder is referred to as cross-attention. How does it differ from self-attention in the encoder?

### âœ… Answer

Self-attention in the decoder is referred to as cross-attention because it involves attending to the encoder's output while generating each token in the decoder. Specifically, in cross-attention, the queries come from the decoder's previous layer, while the keys and values come from the encoder's output, allowing the decoder to focus on relevant parts of the input sequence. 

This differs from self-attention in the encoder, where the attention mechanism operates solely within the input sequence itself, with queries, keys, and values all derived from the same data. Thus, the encoderâ€™s self-attention captures internal dependencies, while the decoderâ€™s cross-attention links the decoder to the encoder representations for contextual generation.

## ğŸ“Œ Q27: What is the softmax function, and where is it applied in the Transformer model?

### âœ… Answer

The softmax function is a mathematical operation that converts a vector of raw scores (logits) into a probability distribution, where each value lies between 0 and 1, and all values sum to 1. In the Transformer model, softmax is applied in the output layer during token prediction to transform the model's raw score outputs into probabilities over the vocabulary, enabling the selection of the most likely next token.

Additionally, softmax is used within the self-attention mechanism to normalize the  attention weights.  This normalization allows the model to weigh the importance of different input tokens effectively. Thus, softmax plays a crucial role in handling probabilities both in self-attention and final predictions.â€‹


**ğŸ‘¨ğŸ»â€ğŸ’» LLM Engineer Toolkit**
--------------------------------------------------------------------------------------------
ğŸ¤– This repository contains a curated list of 120+ LLM, RAG and Agent related libraries category wise. 

ğŸ‘‰ [Repo link](https://github.com/KalyanKS-NLP/llm-engineer-toolkit) 

This repository is highly useful for Data Scientists, AI/ML Engineers working with LLM, RAG and Agents.

![LLM Engineer Toolkit](images/llm-engineer-toolkit.jpg)
 

---------------------------------------------------------------------------------------------





